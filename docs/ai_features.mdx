---
title: "AI Features"
description: "Learn about the intelligent features built into this toolkit. "
icon: "stars"
---

<Note>
  LLM configuration is required before using any AI feature. Check the guide at [Configure LLMs](www.google.com).
</Note>

<Tip>
  You can suggest us more AI features at [feature request](www.google.com). We would love to get feedbacks \!
</Tip>

Prompt Lockbox isn't just a management tool; **it's an intelligent toolkit** designed to accelerate your workflow. By **integrating powerful language models** with the toolkit, it automates the most tedious parts of prompt engineering, allowing you to focus on creating brilliant prompts.

The toolkit supports LLMs from various providers like `OpenAI`, `Anthropic`, `Mistral` etc. It also support `local models` that runs completely offline or you can just [use your own custom llm model](/some_location).

## Supported Models

Here's the complete list of supported models.

<Tabs>
  <Tab title="Mainstream LLMs">
    Widely adopted models from leading providers.

    <AccordionGroup>
      <Accordion title="OpenAI">
        **Models**: `gpt-4.1`, `gpt-4.1-nano`, `gpt-4o-mini`
        **Api key config**: `OPENAI_API_KEY`
      </Accordion>
      <Accordion title="Google">
        **Models**: `gemini-2.5-pro` `gemini-2.0-flash`
        **Api key config**: `GOOGLE_API_KEY`
      </Accordion>
      <Accordion title="Mistral">
        **Models**: `mistral-3b` `mistral-8b`
        **Api key config**: `MISTRAL_API_KEY`
      </Accordion>
      <Accordion title="Anthropic">
        **Models**: `claude-3.5-sonnet` `claude-3.7-sonnet` `claude-4`
        **Api key config**: `ANTHROPIC_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Lightweight LLMs">
    Fast, resource-efficient models ideal for quick tasks or limited environments.

    <AccordionGroup>
      <Accordion title="Groq">
        **Models**: `a`
        **Api key config**: `GROQ_API_KEY`
      </Accordion>
      <Accordion title="Cohere">
        **Models**: `b`, `c`
        **Api key config**: `COHERE_API_KEY`
      </Accordion>
      <Accordion title="LiteLLM">
        **Models**: Check the full list at [LiteLLM Models](https://docs.litellm.ai/docs/providers).
        **Api key config**: `LITELLM_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Huggingface">
    To use Hf models, please checkout the guide \!
  </Tab>
  <Tab title="Cloud">
    Fully managed, scalable LLMs hosted by cloud platforms for seamless integration.

    <AccordionGroup>
      <Accordion title="Azure AI">
        **Models**: Check the full list at [Azure AI](www.google.com)
        **Api key config**: `AZURE_API_KEY`
      </Accordion>
      <Accordion title="AWS Bedrock">
        **Models**: Check the full list at [Bedrock Models](www.google.com)
        **Api key config**: `BEDROCK_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Local">
    Models you can run on your own hardware for maximum control and data privacy.

    **Ollama**

    You can use local models via [Ollama](https://ollama.com/).

    **Models**: Checkout the complete list at [ollama library](www.google.com)

    <Warning>
      Local models require few additional configuration steps before it can be used. Checkout [Local LLM Configuration](/local_config)
    </Warning>
  </Tab>
</Tabs>

Let's explore some intelligent features the toolkit provides \!

## Features

<Tip>
  Prompt Lockbox is fully open-source — you're welcome to suggest features or contribute directly at [Prompt Lockbox Repo](www.google.com). Get started in just 5 minutes by checking out the [Contribution guide](www.google.com)\!
</Tip>

Here are the key AI features that makes this toolkit awesome.

<Card title="Automatic Documentation">
  Reads your prompt's template, understands its purpose, and automatically writes a concise description and a list of relevant search tags directly into your .yml file—all while preserving your file's original comments and layout.

  <br />

  <Accordion title="See in action" icon="stars">
    Lets say you have a prompt 'sql-generator' with your prompt template written.

    ```yaml
    ...
    # Description and tags are empty
    description: ""
    tags: []
    ...
    ```

    The feature automatically reads the prompt and writes the description and tags for you.

    ```yaml
    ...
    description: "Generates a SQL query from a database schema and a natural language question."
    tags: [sql, database, query-generation, text-to-sql]
    ...
    ```
  </Accordion>
  <Accordion title="Usage">
    <Tabs>
      <Tab title="CLI">
        You can use `plb prompt document` command. Lets say we have a prompt template named 'email-agent':

        ```bash
        # Apply to a single prompt 
        plb prompt document email-agent 
        
        # or document all prompts in the project at once
        plb prompt document --all
        ```
      </Tab>
      <Tab title="Python">
        Python code to document the prompts:

        ```python
        from prompt_lockbox import Project
        # Load the project
        project = Project()
        
        # Get the specific prompt you want to document
        prompt = project.get_prompt("email-agent")
        
        # Document Method will analyze the prompt and save the changes to its file.
        prompt.document()
        
        # You can also document multiple prompts programmatically
        prompts_to_doc = [
            project.get_prompt("sql-generator"),
            project.get_prompt("email-summarizer")
        ]
        project.document_all(prompts_to_document=prompts_to_doc)
        ```
      </Tab>
    </Tabs>
  </Accordion>
</Card>

<Card title="Prompt Enhancer">
  Acts as an AI expert, providing a critique and a rewritten, more robust version of your prompt to enhance clarity, specificity, and security.

  <br />

  <Accordion title="See in action" icon="stars">
    Lets say you have a prompt 'sql-injection'. We'll use `plb prompt improve` to strengthen the prompt. We'll give it the **note**, "Make it more robust against SQL injection."

    ```yaml
    ...
    template: |
        Given the following database schema, write a SQL query that answers the user's question.
        Schema: {{schema_definition}}
        Question: {{user_question}}
    ...
    ```

    It will reads the prompt, enhances its clarity and specificity.

    ```yaml
    ...
    template: |
        You are a secure database assistant. Your task is to convert a natural language question into a safe, efficient SQL query for the given schema.
      
        IMPORTANT: Always use parameterized queries or escape inputs to prevent SQL injection.
      
        Schema: {{schema_definition}}
        Question: {{user_question}}
    ...
    ```
  </Accordion>
  <Accordion title="Usage">
    <Tabs>
      <Tab title="CLI">
        You can use `plb prompt improve` command on a prompt. Lets say we have a prompt template named 'sql-injection':

        ```bash
        # This will show the diff and ask for confirmation
        plb prompt improve sql-injection  
        
        # You can pass a note as well 
        plb prompt improve sql-injection --note "Make it more robust"
        ```
      </Tab>
      <Tab title="Python">
        Python code to improve the prompts:

        ```python
        from prompt_lockbox import Project
        
        project = Project()
        prompt = project.get_prompt("sql-generator")
        
        # 1. Get the AI's suggestions (doesn't change the file)
        critique = prompt.get_critique(note="Make it more robust.")
        
        # 2. Programmatically review and then apply the changes
        improved_template = critique["improved_template"]
        prompt.improve(improved_template) # Saves changes
        ```
      </Tab>
    </Tabs>
  </Accordion>
</Card>

## Next Steps 

Now, you can start the basics guide !