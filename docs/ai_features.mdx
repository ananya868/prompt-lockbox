---
title: "AI Features"
description: "Learn about the intelligent features built into this toolkit. "
icon: "stars"
---

<Note>
  LLM configuration is required before using any AI feature. Check the guide at [Configure LLMs](/configure_llms).
</Note>

<Tip>
  You can suggest us more AI features at [feature request](/how_to_contribute). We would love to get feedbacks \!
</Tip>

Prompt Lockbox isn't just a management tool; **it's an intelligent toolkit** designed to accelerate your workflow. By **integrating powerful language models** with the toolkit, it automates the most tedious parts of prompt engineering, allowing you to focus on creating brilliant prompts.

The toolkit supports LLMs from various providers like `OpenAI`, `Anthropic`, `Mistral` etc. It also support `local models` that runs completely offline or you can just [use your own custom llm model](/configure_llms).

## Supported Models

Here's the complete list of supported models.

<Tabs>
  <Tab title="Mainstream LLMs">
    Widely adopted models from leading providers.

    <AccordionGroup>
      <Accordion title="OpenAI">
        - **Models**: `gpt-4.1`, `gpt-4.1-nano`, `gpt-4o-mini` and [more](https://platform.openai.com/docs/models).
        - **Api key config**: `OPENAI_API_KEY`
      </Accordion>
      <Accordion title="Google">
        - **Models**: `gemini-2.5-flash-lite` `gemini-2.0-flash` and [more](https://cloud.google.com/vertex-ai/generative-ai/docs/models).
        - **Api key config**: `GOOGLE_API_KEY`
      </Accordion>
      <Accordion title="Mistral">
        - **Models**: `mistral-3b` `mistral-8b` and [more](https://docs.mistral.ai/getting-started/models/models_overview/).
        - **Api key config**: `MISTRAL_API_KEY`
      </Accordion>
      <Accordion title="Anthropic">
        - **Models**: `claude-3.5-sonnet` `claude-3.7-sonnet` `claude-4` and [more](https://docs.anthropic.com/en/docs/about-claude/models/overview)
        - **Api key config**: `ANTHROPIC_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Lightweight LLMs">
    Fast, resource-efficient models ideal for quick tasks or limited environments.

    <AccordionGroup>
      <Accordion title="Groq">
        - **Models**: `gemma2-9b-it` `llama-3.1-8b-instant` `llama-3.3-70b-versatile` and [more](https://console.groq.com/docs/models). 
        - **Api key config**: `GROQ_API_KEY`
      </Accordion>
      <Accordion title="Cohere">
        - **Models**: `command-a-03-2025` `command-r7b-12-2024` `command-r-plus` and [more](https://docs.cohere.com/docs/models).
        - **Api key config**: `COHERE_API_KEY`
      </Accordion>
      <Accordion title="LiteLLM">
        - **Models**: Check the full list at [LiteLLM Models](https://docs.litellm.ai/docs/providers).
        - **Api key config**: `LITELLM_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Huggingface">
    Checkout [Huggingface models](https://huggingface.co/models) for complete list of models. 

    For configuration, checkout [guide](/configure_llms).
  </Tab>
  <Tab title="Cloud">
    Fully managed, scalable LLMs hosted by cloud platforms for seamless integration.

    <AccordionGroup>
      <Accordion title="Azure AI">
        - **Models**: Check the full list at [Azure AI](https://azure.microsoft.com/en-us/products/ai-model-catalog)
        - **Api key config**: `AZURE_API_KEY`
      </Accordion>
      <Accordion title="AWS Bedrock">
        - **Models**: Check the full list at [Bedrock Models](https://aws.amazon.com/bedrock/?trk=33b5edcf-0d26-4e1d-b868-603c42c06eaf&sc_channel=ps&ef_id=Cj0KCQjwmqPDBhCAARIsADorxIYA-Zst0mG1KXW65pzxwXsSjkYZWd5QjEIK4Fdr5XRgjXAdxDvx-_IaAs3aEALw_wcB:G:s&s_kwcid=AL!4422!3!692062173500!e!!g!!amazon%20bedrock!21054971903!164977109691&gad_campaignid=21054971903&gclid=Cj0KCQjwmqPDBhCAARIsADorxIYA-Zst0mG1KXW65pzxwXsSjkYZWd5QjEIK4Fdr5XRgjXAdxDvx-_IaAs3aEALw_wcB)
        - **Api key config**: `BEDROCK_API_KEY`
      </Accordion>
    </AccordionGroup>
  </Tab>
  <Tab title="Local">
    Models you can run on your own hardware for maximum control and data privacy.

    **Ollama**

    You can use local models via [Ollama](https://ollama.com/).

    **Models**: Checkout the complete list at [ollama library](https://ollama.com/library)

    <Warning>
      Local models require few additional configuration steps before it can be used. Checkout [Local LLM Configuration](/configure_llms#local-model-configuration-ollama)
    </Warning>
  </Tab>
</Tabs>

Let's explore some intelligent features the toolkit provides \!

## Features

<Tip>
  Prompt Lockbox is fully open-source — you're welcome to suggest features or contribute directly at [Prompt Lockbox Repo](https://github.com/ananya868/prompt-lockbox/). Get started in just 5 minutes by checking out the [Contribution guide](/how_to_contribute)\!
</Tip>

Here are the key AI features that makes this toolkit awesome.

<Card title="Automatic Documentation">
  Reads your prompt's template, understands its purpose, and automatically writes a concise description and a list of relevant search tags directly into your .yml file—all while preserving your file's original comments and layout.

  <br />

  <Accordion title="See in action" icon="stars">
    Lets say you have a prompt 'sql-generator' with your prompt template written.

    ```yaml
    ...
    # Description and tags are empty
    description: ""
    tags: []
    ...
    ```

    The feature automatically reads the prompt and writes the description and tags for you.

    ```yaml
    ...
    description: "Generates a SQL query from a database schema and a natural language question."
    tags: [sql, database, query-generation, text-to-sql]
    ...
    ```
  </Accordion>
  <Accordion title="Usage">
    <Tabs>
      <Tab title="CLI">
        You can use `plb prompt document` command. Lets say we have a prompt template named 'email-agent':

        ```bash
        # Apply to a single prompt 
        plb prompt document email-agent 
        
        # or document all prompts in the project at once
        plb prompt document --all
        ```
      </Tab>
      <Tab title="Python">
        Python code to document the prompts:

        ```python
        from prompt_lockbox import Project
        # Load the project
        project = Project()
        
        # Get the specific prompt you want to document
        prompt = project.get_prompt("email-agent")
        
        # Document Method will analyze the prompt and save the changes to its file.
        prompt.document()
        
        # You can also document multiple prompts programmatically
        prompts_to_doc = [
            project.get_prompt("sql-generator"),
            project.get_prompt("email-summarizer")
        ]
        project.document_all(prompts_to_document=prompts_to_doc)
        ```
      </Tab>
    </Tabs>
  </Accordion>
</Card>

<Card title="Prompt Enhancer">
  Acts as an AI expert, providing a critique and a rewritten, more robust version of your prompt to enhance clarity, specificity, and security.

  <br />

  <Accordion title="See in action" icon="stars">
    Lets say you have a prompt 'sql-injection'. We'll use `plb prompt improve` to strengthen the prompt. We'll give it the **note**, "Make it more robust against SQL injection."

    ```yaml
    ...
    template: |
        Given the following database schema, write a SQL query that answers the user's question.
        Schema: {{schema_definition}}
        Question: {{user_question}}
    ...
    ```

    It will reads the prompt, enhances its clarity and specificity.

    ```yaml
    ...
    template: |
        You are a secure database assistant. Your task is to convert a natural language question into a safe, efficient SQL query for the given schema.
      
        IMPORTANT: Always use parameterized queries or escape inputs to prevent SQL injection.
      
        Schema: {{schema_definition}}
        Question: {{user_question}}
    ...
    ```
  </Accordion>
  <Accordion title="Usage">
    <Tabs>
      <Tab title="CLI">
        You can use `plb prompt improve` command on a prompt. Lets say we have a prompt template named 'sql-injection':

        ```bash
        # This will show the diff and ask for confirmation
        plb prompt improve sql-injection  
        
        # You can pass a note as well 
        plb prompt improve sql-injection --note "Make it more robust"
        ```
      </Tab>
      <Tab title="Python">
        Python code to improve the prompts:

        ```python
        from prompt_lockbox import Project
        
        project = Project()
        prompt = project.get_prompt("sql-generator")
        
        # 1. Get the AI's suggestions (doesn't change the file)
        critique = prompt.get_critique(note="Make it more robust.")
        
        # 2. Programmatically review and then apply the changes
        improved_template = critique["improved_template"]
        prompt.improve(improved_template) # Saves changes
        ```
      </Tab>
    </Tabs>
  </Accordion>
</Card>

## Next Steps 

Now, you can start the basics guide!

<CardGroup>
  <Card title="Basics" icon="code" href="/guide/first">
    Learn the essentials of this toolkit.
  </Card>
</CardGroup>